---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: Multimodal Frame Identification with Multilingual Evaluation
subtitle: ''
summary: ''
authors:
- Teresa Botschen
- Iryna Gurevych
- Jan-Christoph Klie
- Hatem Mousselly-Sergieh
- Stefan Roth
tags: []
categories: []
date: '2018-06-01'
lastmod: 2020-09-26T12:38:18+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2020-09-26T10:38:18.695424Z'
publication_types:
- 1
abstract: An essential step in FrameNet Semantic Role Labeling is the Frame Identification
  (FrameId) task, which aims at disambiguating a situation around a predicate. Whilst
  current FrameId methods rely on textual representations only, we hypothesize that
  FrameId can profit from a richer understanding of the situational context. Such
  contextual information can be obtained from common sense knowledge, which is more
  present in images than in text. In this paper, we extend a state-of-the-art FrameId
  system in order to effectively leverage multimodal representations. We conduct a
  comprehensive evaluation on the English FrameNet and its German counterpart SALSA.
  Our analysis shows that for the German data, textual representations are still competitive
  with multimodal ones. However on the English data, our multimodal FrameId approach
  outperforms its unimodal counterpart, setting a new state of the art. Its benefits
  are particularly apparent in dealing with ambiguous and rare instances, the main
  source of errors of current systems. For research purposes, we release (a) the implementation
  of our system, (b) our evaluation splits for SALSA 2.0, and (c) the embeddings for
  synsets and IMAGINED words.
publication: '*Proceedings of the 2018 Conference of the North American Chapter of
  the Association for Computational Linguistics: Human Language Technologies, Volume
  1 (Long Papers)*'
url_pdf: https://www.aclweb.org/anthology/N18-1134
doi: 10.18653/v1/N18-1134
---
